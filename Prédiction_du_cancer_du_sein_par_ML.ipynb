{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prédiction du cancer du sein par ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKGruA+KVDs+jGIc5Kngzj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaoIzoo/AI-DEPLOYMENT/blob/main/Pr%C3%A9diction_du_cancer_du_sein_par_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Prédiction du cancer du  sein par machine learning"
      ],
      "metadata": {
        "id": "1n3qWaygvggZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "À propos de l'ensemble de données\n",
        "\n",
        "Les caractéristiques sont calculées à partir d'une image numérisée d'une aspiration à l'aiguille fine (FNA) d'une masse mammaire. Elles décrivent les caractéristiques des noyaux cellulaires présents dans l'image.\n",
        "n l'espace tridimensionnel est celui décrit dans : [K. P. Bennett et O. L. Mangasarian : \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
        "\n",
        "Cette base de données est également disponible sur le site:\n",
        "ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
        "\n",
        "Également disponible sur le dépôt d'apprentissage automatique de l'UCI : https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
        "\n",
        "Informations sur les variables :\n",
        "\n",
        "1) Numéro d'identification\n",
        "2) Diagnostic (M = malin, B = bénin)\n",
        "3-32)\n",
        "\n",
        "Dix caractéristiques à valeur réelle sont calculées pour chaque noyau cellulaire :\n",
        "\n",
        "a) le rayon (moyenne des distances entre le centre et les points du périmètre)\n",
        "b) texture (écart-type des valeurs de l'échelle de gris)\n",
        "c) périmètre\n",
        "d) surface\n",
        "e) régularité (variation locale des longueurs de rayon)\n",
        "f) compacité (périmètre^2 / surface - 1,0)\n",
        "g) concavité (sévérité des parties concaves du contour)\n",
        "h) points concaves (nombre de portions concaves du contour)\n",
        "i) la symétrie\n",
        "j) dimension fractale (\"approximation du trait de côte\" - 1)\n",
        "\n",
        "La moyenne, l'erreur standard ou la plus grande (moyenne des trois plus grandes valeurs) de ces caractéristiques ont été calculées.\n",
        "plus grandes valeurs) de ces caractéristiques ont été calculées pour chaque image,\n",
        "ce qui donne 30 caractéristiques. Par exemple, le champ 3 est le Rayon moyen, le champ 13 est le rayon SE, le champ 23 est le rayon le plus mauvais.\n",
        "\n",
        "Toutes les valeurs des caractéristiques sont recodées avec quatre chiffres significatifs.\n",
        "\n",
        "Valeurs d'attributs manquantes : aucune\n",
        "\n",
        "Distribution des classes : 357 bénignes, 212 malignes\n",
        "\n",
        "Traduit avec www.DeepL.com/Translator (version gratuite)"
      ],
      "metadata": {
        "id": "lXIY_E2OvshK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Importation des packages"
      ],
      "metadata": {
        "id": "XMNhkLl5w4wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import missingno as msno\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "#Pour la construction des différents modèles de ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import xgboost as xg"
      ],
      "metadata": {
        "id": "V3cNGCBGw_MV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploration de la base de donnée"
      ],
      "metadata": {
        "id": "so8Knckhxjh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1) Importation de la base**"
      ],
      "metadata": {
        "id": "IzqYxjr1xszp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importation de la base data.csv\n",
        "import pandas as pd\n",
        "df = pd.read_csv ('/content/data.csv',  sep=',')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "wMBLM3pNxyiV",
        "outputId": "dfd43a5c-2f00-4c95-9780-f389fb941799"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e7838eba8ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# importation de la base data.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data.csv'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"La base de données sur le cancer comprend \", df.shape)"
      ],
      "metadata": {
        "id": "DT_TEj1vyVqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Suppression de la variable unnamed 32 qui ne comporte que des variables manquantes**"
      ],
      "metadata": {
        "id": "sR_m7rRHzAC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# suppression de la colonne \"id\" et \"Unnamed: 32\"\n",
        "df = df.drop(df.columns[[0,32]], axis=1)\n",
        "df.head(30)"
      ],
      "metadata": {
        "id": "3z5g0jiuzLva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2) Analysons la variable à expliquer (Diagnostic)**"
      ],
      "metadata": {
        "id": "vdKjbKYez1x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df['diagnosis'],label=\"Count\")"
      ],
      "metadata": {
        "id": "JF1CGBYg0Emo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nombre total de cancéreuse et non cancéreuse\n",
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "h858qsRi00tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a un nombre plus élévé de cancer de sein benigne que maligne, soit environ 62,7 % et 37,3% de maligne"
      ],
      "metadata": {
        "id": "rMshf_zH2hzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Valeurs manquantes\n",
        "\n",
        "df.isna().sum()\n",
        "msno.bar(df)"
      ],
      "metadata": {
        "id": "xy5iTlA82msz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous n'avons pas de valeurs manquantes dans notre base de données"
      ],
      "metadata": {
        "id": "Tm9qSKol2wIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 Etude la correlation entre les différentes variables**"
      ],
      "metadata": {
        "id": "EFqHtvSo3izD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformation de la variable cible en variable quantitative"
      ],
      "metadata": {
        "id": "J0ZCSxuC4KSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphique de correlation\n",
        "\n",
        "plt.figure(figsize = (20, 12))\n",
        "\n",
        "corr = df.corr()\n",
        "mask = np.triu(np.ones_like(corr, dtype = bool))\n",
        "\n",
        "sns.heatmap(corr, mask = mask, linewidths = 1, annot = True, fmt = \".2f\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_4YXdIdE3q15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons voir qu'il y a beaucoup de colonnes qui sont très fortement corrélées, ce qui provoque la multicollinéarité. Nous devons donc éliminer les caractéristiques fortement corrélées."
      ],
      "metadata": {
        "id": "oQe65VUl5SyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removing highly correlated features\n",
        "\n",
        "corr_matrix = df.corr().abs() \n",
        "\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype = bool))\n",
        "tri_df = corr_matrix.mask(mask)\n",
        "\n",
        "to_drop = [x for x in tri_df.columns if any(tri_df[x] > 0.6)]\n",
        "\n",
        "df = df.drop(to_drop, axis = 1)\n",
        "\n",
        "print(f\"La base de données a été reduit à {df.shape[1]} columns.\")"
      ],
      "metadata": {
        "id": "50gIuc9o5Ya_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "uKW9DOGC566j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remplaçons M ( cancer maligne ) par 1 et B ( cancer benigne ) par 0 sur la colonne \"diagnosis\"\n",
        "df.diagnosis = df.diagnosis.replace({\"M\":1,\"B\":0})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MxJXavltRRZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv()"
      ],
      "metadata": {
        "id": "OAhmbn0l__CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous ne garderons que "
      ],
      "metadata": {
        "id": "gj_eNbosRX5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Implémentation des différents modèles de ML"
      ],
      "metadata": {
        "id": "f8KdBTfq6poK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1 Subdivision de la base de données en données d'apprentissage et test**"
      ],
      "metadata": {
        "id": "9AQjU-nW7OFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divsion en 70 % de données d'apprentissage et 20 % de test"
      ],
      "metadata": {
        "id": "b4S_2K-27eYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('diagnosis', axis = 1)\n",
        "y = df['diagnosis']"
      ],
      "metadata": {
        "id": "uawnXWTI7oOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into training and test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
      ],
      "metadata": {
        "id": "DrfA6qGm_4Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2) Normalisation de nos données**"
      ],
      "metadata": {
        "id": "rfSUXPdJ9oCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous remarquons une très grande variabilté en nos variables. Nous allons proceder à la normalisation de nos données de test."
      ],
      "metadata": {
        "id": "aCqA4lqZ8xwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "R5NpW4xn9_Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x-TkUmTU_Ofj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3) Implémentation**"
      ],
      "metadata": {
        "id": "ncJayqY2_P5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3.1) Regression Logistique"
      ],
      "metadata": {
        "id": "Ve3Ek22F_WWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "predictions1 = logreg.predict(X_test)\n"
      ],
      "metadata": {
        "id": "AqTOJ3MB_jOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions1))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, predictions1))"
      ],
      "metadata": {
        "id": "0TaINlm0DjZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "logreg_acc = accuracy_score(y_test, predictions1)\n",
        "print(\"Accuracy of the Logistic Regression Model is: \", logreg_acc)"
      ],
      "metadata": {
        "id": "h7IG6JUsDuF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3.2) Support Vector Classifier (SVC)"
      ],
      "metadata": {
        "id": "mfeKprbMEhrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "svc = SVC()\n",
        "parameters = {\n",
        "    'gamma' : [0.0001, 0.001, 0.01, 0.1],\n",
        "    'C' : [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(svc, parameters)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ULTYsGisEwQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "C91FBGfyE12I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_score_"
      ],
      "metadata": {
        "id": "406AbNluE5ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(C = 15, gamma = 0.01)\n",
        "svc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "YWQmnCH7E79V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svc.predict(X_test)"
      ],
      "metadata": {
        "id": "wjgcjCHRE-ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score\n",
        "\n",
        "print(accuracy_score(y_train, svc.predict(X_train)))\n",
        "\n",
        "svc_acc = accuracy_score(y_test, svc.predict(X_test))\n",
        "print(svc_acc)"
      ],
      "metadata": {
        "id": "-7Ss59mkFCbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "a0vp6UROFG_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "QP2Us1VRFJi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3.3)  ANN (neural network )"
      ],
      "metadata": {
        "id": "p7ssexrtFhbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialising the ANN\n",
        "\n",
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n",
        "# Adding the third hidden layer\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n",
        "\n",
        "# Adding the fourth hidden layer\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
        "# Compiling the ANN\n",
        "\n",
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'] )\n",
        "\n",
        "# Training the ANN on the training set\n",
        "\n",
        "ann.fit(X_train, y_train, batch_size = 16, epochs = 100)"
      ],
      "metadata": {
        "id": "aVTl_GvUFtXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the test set results\n",
        "\n",
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.9)\n",
        "np.set_printoptions()"
      ],
      "metadata": {
        "id": "p7RQhxJjF3if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the confusion matrix, calculating accuracy_score \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(\"Confusion Matrix\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "47O4GG_PF9IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "ac_ann = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy\")\n",
        "print(ac_ann)"
      ],
      "metadata": {
        "id": "6RY0ZyvcGAZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3.4) Les forêts aléatoires (Random Forests)"
      ],
      "metadata": {
        "id": "UMyRXhF4GZm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rand_clf = RandomForestClassifier(criterion = 'entropy', max_depth = 11, max_features = 'auto', min_samples_leaf = 2, min_samples_split = 3, n_estimators = 130)\n",
        "rand_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "SxSRKudoGn5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rand_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "eelsrunBGwu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score\n",
        "\n",
        "print(accuracy_score(y_train, rand_clf.predict(X_train)))\n",
        "\n",
        "ran_clf_acc = accuracy_score(y_test, y_pred)\n",
        "print(ran_clf_acc)"
      ],
      "metadata": {
        "id": "51NpwWVKGyBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "BrD8GMapG094"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3.5) Support vector Machine "
      ],
      "metadata": {
        "id": "KwYGas1SHGdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_model = SVC(kernel=\"rbf\")\n",
        "svc_model.fit(X_train, y_train)\n",
        "predictions3 = svc_model.predict(X_test)"
      ],
      "metadata": {
        "id": "CTT5cEcsHWMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions3))\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test, predictions3))"
      ],
      "metadata": {
        "id": "TWgEj3sWHaNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_acc = accuracy_score(y_test, predictions3)\n",
        "print(\"Accuracy of SVM model is: \", svm_acc)"
      ],
      "metadata": {
        "id": "IW9aj3NGHdxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Benchmark des différents modèles"
      ],
      "metadata": {
        "id": "A4spwnlJHrDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1 Visualisation de différents resultats"
      ],
      "metadata": {
        "id": "BLTkGZyvHy9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mylist=[]\n",
        "mylist2=[]\n",
        "mylist.append(svc_acc)\n",
        "mylist2.append(\"SVC\")\n",
        "mylist.append(svc_acc)\n",
        "mylist2.append(\"SVC\")\n",
        "mylist.append(logreg_acc)\n",
        "mylist2.append(\"Logistic Regression\")\n",
        "mylist.append(ran_clf_acc)\n",
        "mylist2.append(\"Random Forests\")\n",
        "mylist.append(svm_acc)\n",
        "mylist2.append(\"Support Vector Machines\")\n",
        "mylist.append(ac_ann)\n",
        "mylist2.append(\"ANN\")\n",
        "plt.rcParams['figure.figsize']=22,10\n",
        "sns.set_style(\"darkgrid\")\n",
        "ax = sns.barplot(x=mylist2, y=mylist, palette = \"coolwarm\", saturation =1.5)\n",
        "plt.xlabel(\"Classification Models\", fontsize = 20 )\n",
        "plt.ylabel(\"Accuracy\", fontsize = 20)\n",
        "plt.title(\"Accuracy of different Classification Models\", fontsize = 20)\n",
        "plt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 8)\n",
        "plt.yticks(fontsize = 13)\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy() \n",
        "    ax.annotate(f'{height:.2%}', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A7u0YN7qH_kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le meilleur modèle  en terme d'accuracy est le SVC"
      ],
      "metadata": {
        "id": "CG26i41pIL00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testons les performances du SVC**"
      ],
      "metadata": {
        "id": "OidVirZ8ItgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sauvegarde et importation de notre modèle"
      ],
      "metadata": {
        "id": "hP_fQvjYSGAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "N1nuN6YUSpGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enregistrer mon modèle**"
      ],
      "metadata": {
        "id": "euLvSGAdTCsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "XOaDMOZyed1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'trained_model.sav'\n",
        "pickle.dump(svc, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "9S3YrqqVTIEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = pickle.load(open('trained_model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "ZhQnvmJyxgIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = (0.7452,1003,0.1,0.002897,23.87,0.22,0.2908,0.07277)\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "prediction = loaded_model.predict(input_data_reshaped)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "  print('La personne a un cancer benigne')\n",
        "else:\n",
        "  print('La personne a un cancer maligne')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCic7zrAj3fg",
        "outputId": "febfd5de-a8b7-47ed-8b7c-3431e0aeab1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "La personne a un cancer maligne\n"
          ]
        }
      ]
    }
  ]
}